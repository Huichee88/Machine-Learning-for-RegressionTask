# -*- coding: utf-8 -*-
"""EDA+ Hypothesis + Heatmap + ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wAPYIX8ZaB_ejqdP2JvFDSQ1C4vUqQu5

#Dependencies
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns
from scipy.stats import ttest_ind
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
import statsmodels.api as sm
from sklearn.model_selection import  train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import learning_curve
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import f1_score
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

pip install eli5

import eli5
from eli5.sklearn import PermutationImportance

"""#Import the dataset"""

df = pd.read_csv('/content/summer-products-with-rating-and-performance_2020-08.csv')

df.info()

df.head(5)

"""#Search for missing values and duplicates """

df.isnull().sum()

#percentage of missing values 

missing_percentage = df.isnull().sum()/ len(df) * 100 

print(missing_percentage)

#more than 30% can del 
del df['urgency_text']
del df['merchant_profile_picture']

del df['has_urgency_banner']

#percentage of missing values 

missing_percentage = df.isnull().sum()/ len(df) * 100 

print(missing_percentage)

"""#Median imputation for numerical missing values

"""

num_cols = df.select_dtypes(include=['number']).columns.tolist()

num_cols

num_missing = df.select_dtypes(include='number').isnull().sum()
num_missing = num_missing[num_missing > 0]
print(num_missing)

median = df['rating_five_count'].median()

df['rating_five_count'].fillna(median, inplace=True)

median = df['rating_four_count'].median()

df['rating_four_count'].fillna(median, inplace =True)

median = df['rating_three_count'].median()

df['rating_three_count'].fillna(median, inplace =True)

median = df['rating_two_count'].median()

df['rating_two_count'].fillna(median, inplace =True)

median = df['rating_one_count'].median()

df['rating_one_count'].fillna(median, inplace=True)



"""#Mode imputation of categorical missing value

"""

cat_missing = df.select_dtypes(include='object').isnull().sum()
cat_missing = cat_missing[cat_missing > 0]
print(cat_missing)

mode = df['product_color'].mode().iloc[0]

df['product_color'].fillna(mode, inplace=True)

mode = df['product_variation_size_id'].mode().iloc[0]

df['product_variation_size_id'].fillna(mode, inplace=True)

mode = df['origin_country'].mode().iloc[0]

df['origin_country'].fillna(mode, inplace=True)

mode = df['merchant_name'].mode().iloc[0]

df['merchant_name'].fillna(mode, inplace=True)

mode = df['merchant_info_subtitle'].mode().iloc[0]

df['merchant_info_subtitle'].fillna(mode, inplace=True)

"""#Check if there is any missing value left"""

#check if there is still missing values
print(df.isnull().values.sum() !=0)

"""#Remove some columns


"""

del df['title_orig']

"""#Check for duplicates"""

df.duplicated().any()

dupes=df.duplicated()
#dupes
sum(dupes)

#dropping duplicate values

df = df.drop_duplicates()
df

#we can also drop duplicate values like that :---

# imp.drop_duplicates(inplace=True)

# dropping = imp.copy()
# dropping

df.duplicated().any()

"""#Change to date time format

"""

df['crawl_month']= pd.to_datetime(df['crawl_month'])

"""#Calculate count, mean, std, min, 25%, 50%, 75%, max values for each column. Prepare an analysis of the difference between mean and median for each column and possible reasons for the same."""

df.describe()

round(df.describe())

"""#Data Visualization

Data visualization: This involves creating various types of plots and charts to visualize the distribution, relationships, and trends in the data, such as histograms, scatter plots, box plots, and heatmaps.

##Histogram
"""

num_cols = df.select_dtypes(include=['number']).columns.tolist()

num_cols

columns_to_plot = ['price',
 'retail_price',
 'units_sold',
 'uses_ad_boosts',
 'badges_count',
 'badge_local_product',
 'badge_product_quality',
 'badge_fast_shipping',
 'product_variation_inventory',
 'shipping_option_price',
 'shipping_is_express',
 'countries_shipped_to',
 'inventory_total',
 'merchant_rating_count',
 'merchant_rating',
 'merchant_has_profile_picture']

# create a histogram for each column
for col in columns_to_plot:
    plt.hist(df[col], bins=10)
    plt.title(col)
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.show()

"""##Boxplot"""

#Boxplot

columns_to_plot2 = ['rating',
 'rating_count',
 'rating_five_count',
 'rating_four_count',
 'rating_three_count',
 'rating_two_count',
 'rating_one_count']

# create boxplot for ratings 

for col in columns_to_plot2:
  plt.boxplot(df[col])
  plt.title(col)
  plt.show()

"""Seems like there is alot of outliers in the ratings. """

cat_cols = df.select_dtypes(include=['object']).columns.tolist()

cat_cols

plt.scatter(df['currency_buyer'], df['price'])

plt.title('Price by currencyBuyer')

plt.ylabel('price')
plt.xlabel('currency')

plt.show()

plt.scatter(df['origin_country'], df['price'])

plt.title('Price by origin_country')

plt.ylabel('price')
plt.xlabel('country')

plt.show()

plt.scatter(df['origin_country'], df['retail_price'])

plt.title('retail_price by origin_country')

plt.ylabel('retail_price')
plt.xlabel('country')

plt.show()

#Price vs retail price

#scatter plot with price against retail price       #THIS ONE IS NUMERICAL VS NUMERICAL  (CAN/ CORRECT)
plt.plot(df['retail_price'])
plt.plot(df['price'])

#Title
plt.title('price VS retail_price')

#setting labels X and Y
plt.xlabel('price')
plt.ylabel('retail_price')

plt.show()

"""The overall data science project flow involves a series of steps or phases that are typically followed to solve a business problem or answer a research question using data. Although the exact steps may vary depending on the project, data, and stakeholders involved, a typical data science project flow may include the following:

Problem formulation: In this phase, the problem or question is defined, and the goals and objectives of the project are established. The key stakeholders and data sources are identified, and the project scope and timeline are determined.

Data collection: In this phase, the data required for the analysis is collected from various sources and consolidated into a single dataset. Data cleaning and preprocessing are also performed to remove missing values, outliers, and other data quality issues that could affect the analysis.

Exploratory data analysis (EDA): In this phase, the data is visualized and summarized to gain insights and identify potential issues or opportunities for further analysis. This includes creating various types of plots and charts, calculating descriptive statistics, and testing hypotheses.

Feature engineering: In this phase, the most important features or variables that explain the variation in the data are identified and selected using techniques such as PCA, feature selection, or feature extraction. New features may also be created by combining or transforming existing features.

Model selection and training: In this phase, the appropriate modeling technique is selected based on the nature of the problem and the data. The data is split into training and testing sets, and the model is trained on the training data using various algorithms and hyperparameters. The model is also evaluated on the testing data to check for overfitting or underfitting.

Model evaluation and validation: In this phase, the performance of the model is evaluated using various metrics such as accuracy, precision, recall, F1 score, and AUC-ROC. The model is also validated using techniques such as cross-validation, bootstrap, or permutation testing to ensure its robustness and generalizability.

Model deployment: In this phase, the model is integrated into the business process or application to make predictions or generate insights. The results are communicated to the stakeholders in a clear and actionable manner using visualizations, dashboards, or reports.

Model monitoring and maintenance: In this phase, the model is monitored and maintained over time to ensure its performance remains optimal and up-to-date. This includes monitoring for data drift, concept drift, or model decay, and retraining or updating the model as needed.

#Hypothesis Testing 

Predict the price.. 

Target variable: price

The key difference between hypothesis testing and ANOVA is that hypothesis testing is used to test a single hypothesis, whereas ANOVA is used to test multiple hypotheses simultaneously.
"""

#H0 = retail price has no effect on price 
#H1 = retail price has effect on price 

# conduct a two-sample t-test
t_stat, p_value = ttest_ind(df['retail_price'], df['price'])

# print the results
print('t-statistic:', t_stat)
print('p-value:', p_value)

# interpret the results
if p_value < 0.05:
    print('Reject null hypothesis: retail price has effect on price ')
else:
    print('Fail to reject null hypothesis: retail price has no effect on price ')

#H0 = currency_buyer has no effect on price 
#H1 = currency_buyer has effect on price  

df['currency_buyer'] = pd.to_numeric(df['currency_buyer'], errors='coerce')

# conduct a two-sample t-test
t_stat, p_value = ttest_ind(df['currency_buyer'], df['price'])

# print the results
print('t-statistic:', t_stat)
print('p-value:', p_value)

# interpret the results
if p_value < 0.05:
    print('Reject null hypothesis:currency_buyer has effect on price   ')
else:
    print('Fail to reject null hypothesis: currency_buyer has no effect on price  ')     #no result in pvalue and ttest because the curencybuyer is not numeric....

#H0 = units_sold has no effect on price 
#H1 = units_sold has effect on price  

t_stat, p_value = ttest_ind(df['units_sold'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: units_sold has effect on price')
else: 
  print('Fail to reject null hypothesis: units_sold has no effect on price')

#H0 = uses_ad_boosts has no effect on price 
#H1 = uses_ad_boosts has effect on price  


t_stat, p_value = ttest_ind(df['uses_ad_boosts'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: uses_ad_boosts has effect on price')
else: 
  print('Fail to reject null hypothesis: uses_ad_boosts has no effect on price')

#H0 = rating has no effect on price 
#H1 = rating has effect on price  

t_stat, p_value = ttest_ind(df['rating'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: rating has effect on price')
else: 
  print('Fail to reject null hypothesis: rating has no effect on price')

#H0 = badges_count has no effect on price 
#H1 = badges_count has effect on price  

t_stat, p_value = ttest_ind(df['badges_count'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: badges_count has effect on price')
else: 
  print('Fail to reject null hypothesis: badges_count has no effect on price')

#H0 = badge_product_quality has no effect on price 
#H1 = badge_product_quality has effect on price  

t_stat, p_value = ttest_ind(df['badge_product_quality'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: badge_product_quality has effect on price')
else: 
  print('Fail to reject null hypothesis: badge_product_quality has no effect on price')

#H0 = badge_fast_shipping has no effect on price 
#H1 = badge_fast_shipping has effect on price  

t_stat, p_value = ttest_ind(df['badge_fast_shipping'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: badge_fast_shipping has effect on price')
else: 
  print('Fail to reject null hypothesis: badge_fast_shipping has no effect on price')

#H0 = tags has no effect on price 
#H1 = tags has effect on price  

df['tags'] = pd.to_numeric(df['tags'], errors='coerce')

t_stat, p_value = ttest_ind(df['tags'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: tags has effect on price')
else: 
  print('Fail to reject null hypothesis: tags has no effect on price')   #tags is categorical thats why no tstats, and p-value results...

#H0 = shipping_option_price has no effect on price 
#H1 = shipping_option_price has effect on price  

t_stat, p_value = ttest_ind(df['shipping_option_price'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: shipping_option_price has effect on price')
else: 
  print('Fail to reject null hypothesis: shipping_option_price has no effect on price')

#H0 = shipping_is_express has no effect on price 
#H1 = shipping_is_express has effect on price  

t_stat, p_value = ttest_ind(df['shipping_is_express'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: shipping_is_express has effect on price')
else: 
  print('Fail to reject null hypothesis: shipping_is_express has no effect on price')

#H0 = countries_shipped_to has no effect on price 
#H1 = countries_shipped_to has effect on price  

t_stat, p_value = ttest_ind(df['countries_shipped_to'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: countries_shipped_to has effect on price')
else: 
  print('Fail to reject null hypothesis: countries_shipped_to has no effect on price')

#H0 = theme has no effect on price 
#H1 = theme has effect on price  

df['theme'] = pd.to_numeric(df['theme'], errors='coerce')

t_stat, p_value = ttest_ind(df['theme'], df['price'])

print('t-statistics:', t_stat)
print('p-value:', p_value)

if p_value <0.05: 
  print('Reject null hypothesis: theme has effect on price')
else: 
  print('Fail to reject null hypothesis: theme has no effect on price')  #tags is categorical thats why no tstats, and p-value results...

"""#Feature scaling """

#Checking the Ranges of the independent variables and dependent variable 
plt.figure(figsize=(20,7))
plt.xticks(rotation= 'vertical')
sns.boxplot(data=df)

"""#Min max scaling"""

scaler = MinMaxScaler()

num_cols = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]

for col in num_cols:
    df[col] = scaler.fit_transform(df[[col]])

plt.figure(figsize=(20,7))
plt.xticks(rotation= 'vertical')
sns.boxplot(data=df)

"""#Standardization """

scaler = StandardScaler()

num_cols = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]

for col in num_cols:
    df[col] = scaler.fit_transform(df[[col]])

plt.figure(figsize=(20,7))
plt.xticks(rotation= 'vertical')
sns.boxplot(data=df)

"""#Outlier Treatment  (hold first ... )

#Label encoding
"""

df_encoded = df.copy()

for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df[col])

df= df_encoded
df.info()

"""# Heatmap ( Feature selection )"""

df.corr()

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True );
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

del df['rating_five_count']
del df['rating_four_count']
del df['rating_three_count']
del df['rating_two_count']
del df['rating_one_count']
del df['badge_product_quality']
del df['product_url']
del df['product_picture']
del df['currency_buyer']
del df['shipping_option_price']

del df['rating_count']

plt.figure(figsize=(20,20))
sns.heatmap(df.corr(), annot=True );
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

model = sm.OLS(df['price'], df[[
 'retail_price',
 'units_sold',
 'uses_ad_boosts',
 'rating',
 'badges_count',
 'badge_local_product',
 'badge_fast_shipping',
 'product_variation_inventory',
 'shipping_is_express',
 'countries_shipped_to',
 'inventory_total',
 'merchant_rating_count',
 'merchant_rating',
 'merchant_has_profile_picture']]).fit()

model.summary()

#remove those variables that are not significant... 
del df['rating']
del df['uses_ad_boosts']
del df['badges_count']
del df['badge_local_product']
del df['badge_fast_shipping']
del df['merchant_rating_count']
del df['merchant_rating']
del df['merchant_has_profile_picture']

df.info()

"""#declare X and Y """

df['crawl_month'] = pd.to_numeric(pd.to_datetime(df['crawl_month']), errors='coerce')

X = df[['title',
        'retail_price',
        'units_sold',
        'tags',
        'product_color',
        'product_variation_size_id',
        'shipping_option_name',
        'origin_country',
        'merchant_title',
        'merchant_name',
        'merchant_info_subtitle',
        'merchant_id',
        'product_id',
        'theme',
        'crawl_month',
        'product_variation_inventory',
        'shipping_is_express',
        'countries_shipped_to',
        'inventory_total']]

y = df['price']

"""#Train test Split 80:20 """

#Spliting data into Training 80%, Testing 20% 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, y_train.shape , X_test.shape, y_test.shape

"""##Linear Regression """

LR_model = LinearRegression()

LR_model.fit(X_train,y_train)

LR_pred = LR_model.predict(X)

print('Coefficients:', LR_model.coef_)
print('Intercept:', LR_model.intercept_)

# Print the predicted values
print('Predicted values:', LR_pred)

lr_pred = LR_model.predict(X_test)

train_sizes, train_scores, test_scores = learning_curve(LR_model, X_train, y_train, cv=20)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)

test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.plot(train_sizes, train_mean, label="Training score")
plt.plot(train_sizes, test_mean, label="Cross-validation score")

plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)

plt.xlabel("Number of training samples")
plt.ylabel("Score")
plt.legend(loc="best")

plt.show()

train_mse = mean_squared_error(y_train, LR_model.predict(X_train))
test_mse = mean_squared_error(y_test, LR_model.predict(X_test))

train_mae = mean_absolute_error(y_train, LR_model.predict(X_train))
test_mae = mean_absolute_error(y_test, LR_model.predict(X_test))


train_mse, test_mse, train_mae, test_mae

"""In this case, the training set has an MSE of 0.79004075166609 and a MAE of 0.6829264539441532, while the test set has an MSE of 0.7945367924090353 and a MAE of 0.6914542142171691. These metrics suggest that the model may be slightly overfitting, as the test set performance is slightly worse than the training set performance."""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
import numpy as np


# Perform 5-fold cross-validation and calculate the mean R^2 score
scores = cross_val_score(LR_model, X, y, cv=5, scoring='r2')
print('Mean R^2 score:', np.mean(scores))

#Higher Mean R2 is better...

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# calculate the evaluation metrics
mae = mean_absolute_error(y_test, lr_pred)
rmse = np.sqrt(mean_squared_error(y_test, lr_pred))
r2 = r2_score(y_test, lr_pred)
mape = mean_absolute_percentage_error(y_test, lr_pred)

# print the evaluation metrics
print("Mean Absolute Error:", mae)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)
print("Mean Absolute Percentage Error:", mape)

print(len(y_test))
print(len(lr_pred))

perm = PermutationImportance(LR_model, random_state=1).fit(X_test, y_test)
eli5.show_weights(perm, feature_names = X_test.columns.tolist(), top=50)

del df['theme']
del df['crawl_month']
del df['shipping_is_express']
del df['merchant_name']
del df['tags']
del df['shipping_option_name']
del df['merchant_info_subtitle']

"""#Linear regression 2"""

df.info()

X = df.drop('price', axis=1)
y = df['price']

#Spliting data into Training 80%, Testing 20% 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, y_train.shape , X_test.shape, y_test.shape

LR2_model = LinearRegression()

LR2_model.fit(X_train,y_train)


print('Coefficients:', LR_model.coef_)
print('Intercept:', LR_model.intercept_)

lr2_pred = LR2_model.predict(X_test)

train_sizes, train_scores, test_scores = learning_curve(LR2_model, X_train, y_train, cv=20)

train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)

test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

plt.plot(train_sizes, train_mean, label="Training score")
plt.plot(train_sizes, test_mean, label="Cross-validation score")

plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1)

plt.xlabel("Number of training samples")
plt.ylabel("Score")
plt.legend(loc="best")

plt.show()

train_mse = mean_squared_error(y_train, LR2_model.predict(X_train))
test_mse = mean_squared_error(y_test, LR2_model.predict(X_test))

train_mae = mean_absolute_error(y_train, LR2_model.predict(X_train))
test_mae = mean_absolute_error(y_test, LR2_model.predict(X_test))


train_mse, test_mse, train_mae, test_mae

# Perform 5-fold cross-validation and calculate the mean R^2 score
scores = cross_val_score(LR2_model, X, y, cv=5, scoring='r2')
print('Mean R^2 score:', np.mean(scores))

# calculate the evaluation metrics
mae = mean_absolute_error(y_test, lr2_pred)
rmse = np.sqrt(mean_squared_error(y_test, lr2_pred))
r2 = r2_score(y_test, lr2_pred)
mape = mean_absolute_percentage_error(y_test, lr2_pred)

# print the evaluation metrics
print("Mean Absolute Error:", mae)
print("Root Mean Squared Error:", rmse)
print("R-squared:", r2)
print("Mean Absolute Percentage Error:", mape)